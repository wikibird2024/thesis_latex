
\subsection{Máy chủ: Quản lý và Xử lý Dữ liệu Trung tâm}
\label{sec:server_overview}

Máy chủ Python đóng vai trò là \textbf{"bộ não"} trung tâm, chịu trách nhiệm \textbf{kết hợp thông minh} dữ liệu từ hai nguồn độc lập: 
\begin{enumerate}
    \item \textbf{ESP32 (cảm biến chuyển động)}: Triển khai tại hiện trường, gửi dữ liệu trạng thái té ngã và GPS qua MQTT.
    \item \textbf{Camera IP (xử lý thị giác)}: Chạy trên máy chủ hoặc máy tính chuyên dụng, thực hiện phát hiện người, theo dõi đối tượng và ước lượng tư thế bằng AI.
\end{enumerate}

Máy chủ nhận kết quả từ hai nguồn này, hợp nhất để đưa ra quyết định phát hiện té ngã đáng tin cậy, đa dạng phạm vi đồng thời kích hoạt cảnh báo và ghi nhận sự kiện.

\subsubsection{Kiến trúc Hệ thống}
\label{subsubsec:system_overview}

Hệ thống máy chủ được thiết kế theo mô hình phân tầng và mô-đun hóa. Như minh họa trong Hình~\ref{fig:system_architecture}:

\begin{itemize}
    \item \textbf{Lớp thu nhận dữ liệu từ các module độc lập}:
    \begin{itemize}
        \item \texttt{comm/}: Nhận dữ liệu ESP32 qua MQTT, API Bot Telegram, kích hoạt AMI.
        \item \texttt{detection/}: Nhận dữ liệu video từ camera IP, xử lý thị giác máy tính.
    \end{itemize}
    \item \textbf{Lớp xử lý tổng hợp}: \texttt{fall/} + \texttt{processing/} tổng hợp dữ liệu từ hai module để ra quyết định té ngã.
    \item \textbf{Lớp đầu ra}: \texttt{database/} ghi sự kiện, \texttt{comm/} gửi cảnh báo qua Telegram/AMI.
\end{itemize}

\begin{table}[H]
\centering
\caption{Cấu trúc các mô-đun máy chủ và vai trò}
\label{tab:server_modules}
\begin{tabular}{|l|l|p{7cm}|}
\hline
\textbf{Module} & \textbf{Lớp (Layer)} & \textbf{Vai trò và chức năng} \\
\hline
\texttt{comm/} & ESP32 Input & Nhận dữ liệu MQTT từ ESP32, Telegram Bot, và AMI để gửi cảnh báo \\
\hline
\texttt{detection/} & Vision Input & Xử lý khung hình từ camera IP, phát hiện con người, theo dõi, ước lượng tư thế \\
\hline
\texttt{fall/} & Processing & Thuật toán phát hiện té ngã, kết hợp dữ liệu từ ESP32 và camera \\
\hline
\texttt{processing/} & Processing & \texttt{DetectionProcessor} xử lý đồng bộ, pipeline tiền xử lý, kết hợp dữ liệu \\
\hline
\texttt{database/} & Storage & Ghi lại các sự kiện vào \texttt{fall\_events.db}, quản lý lịch sử \\
\hline
\texttt{config/} & Support & Cấu hình MQTT, AI, cơ sở dữ liệu, AMI, Telegram \\
\hline
\texttt{models/} & Support & Lưu trữ mô hình YOLOv8n và trọng số (weights) \\
\hline
\texttt{utils/} & Support & Công cụ trực quan hóa, overlay skeleton, tiện ích debug \\
\hline
\texttt{tests/} & Testing & Script để kiểm tra logic phát hiện té ngã \\
\hline
\texttt{main.py} & Entry point & Vòng lặp chính, nhận dữ liệu ESP32 và camera, kết hợp, đưa ra quyết định \\
\hline
\end{tabular}
\end{table}

\subsubsection{Luồng Xử lý Máy chủ}
\label{subsubsec:server_flow}


\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/server_flow.pdf}
\caption{Luồng dữ liệu và xử lý trên máy chủ: kết hợp ESP32 và IP Camera thông qua \textbf{DetectionProcessor}.}
\label{fig:server_flow}
\end{figure}
\subsubsection{Kết hợp Dữ liệu Đa phương thức}
\label{subsubsec:multi_input_fusion}

Các module ESP32 và Camera IP hoàn toàn độc lập, máy chủ chỉ chịu trách nhiệm:
\begin{itemize}
    \item Thu nhận kết quả từ ESP32 (MQTT JSON) và camera (AI).
    \item Đồng bộ hóa dữ liệu dựa trên timestamp.
    \item Kết hợp dữ liệu bằng logic AND/OR với trọng số dựa trên độ tin cậy nguồn.
    \item Kích hoạt cảnh báo và ghi nhận sự kiện.
\end{itemize}

\begin{minted}[linenos, frame=lines, fontsize=\small, bgcolor=lightgray, breaklines]{python}
# DetectionProcessor: core fusion logic
async def process_person(frame, person_id, box, landmarks, mqtt_msg):
    """
    Process individual person: fuse Camera + ESP32, draw visuals, send alerts.
    """
    # 1. Initialize FallDetector for new person
    if person_id not in fall_detectors:
        fall_detectors[person_id] = FallDetector()
        person_status[person_id] = 'normal'

    # 2. Check MQTT message
    mqtt_status = None
    if mqtt_msg and mqtt_msg.get('device_id') == f"ESP32_DEV_{person_id}":
        mqtt_status = mqtt_msg

    # 3. Detect fall
    is_fall = fall_detectors[person_id].detect_fall(landmarks, mqtt_status)

    # 4. Update status
    person_status[person_id] = 'fall' if is_fall else 'normal'

    # 5. Draw visuals
    draw_bounding_box(frame, box, person_id, person_status[person_id])
    if landmarks:
        draw_skeleton(frame, landmarks)

    # 6. Handle alerts
    if is_fall:
        fall_id = insert_fall_event(mqtt_msg or {...})
        alert_msg = f"Fall detected. Event ID: {fall_id}"
        await ami_trigger.alert_devices(alert_msg)
        if telegram_bot:
            _, img_encoded = cv2.imencode('.jpg', frame)
            await telegram_bot.send_photo(img_encoded.tobytes(), alert_msg)
\end{minted}

\subsubsection{Lưu trữ và Cảnh báo}
\label{subsubsec:data_storage_alerts}

SQLite logs fall events into \texttt{fall\_events.db}:

\begin{minted}[linenos, frame=lines, fontsize=\small, bgcolor=lightgray, breaklines]{sql}
CREATE TABLE fall_events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    confidence REAL NOT NULL,
    sensor_data TEXT,
    pose_data TEXT,
    alert_status INTEGER DEFAULT 0,
    snapshot TEXT
);
\end{minted}

Main loop collects asynchronous data, processes each module, fuses, and triggers alerts:

\begin{minted}[linenos, frame=lines, fontsize=\small, bgcolor=lightgray, breaklines]{python}
while system_is_running:
    # Collect data from ESP32 and camera
    frame = camera_thread.get_latest_frame()
    sensor_data = mqtt_thread.get_latest_data()
    
    # AI processing
    detections = human_detector.process(frame)
    poses = pose_estimator.process(detections)
    
    # Data fusion
    fall_detected, confidence = fall_detector.analyze(poses, sensor_data)
    
    if fall_detected:
        alert_manager.trigger_notifications(confidence)
        database.log_event(poses, sensor_data, confidence)
\end{minted}

\subsubsection{Cấu trúc thư mục dự án (phiên bản rút gọn)}
\label{subsubsec:project_structure}

To illustrate in the report, auxiliary files and \texttt{\_\_pycache\_\_} are omitted:

\begin{minted}[fontsize=\footnotesize, breaklines, frame=single, linenos]{text}
intergrate_fall/
├── comm/
│   ├── ami_trigger.py
│   ├── mqtt_client.py
│   └── telegram_bot.py
├── config/
│   └── config.py
├── database/
│   └── database_manager.py
├── detection/
│   ├── human_detector.py
│   ├── person_tracker.py
│   └── skeleton_tracker.py
├── fall/
│   └── fall_detector.py
├── processing/
│   └── detection_processor.py
├── utils/
│   └── draw_utils.py
├── models/
│   └── __init__.py
├── tests/
│   └── test_fall.py
├── main.py
├── fall_events.db
├── yolov8n.pt
\end{minted}
